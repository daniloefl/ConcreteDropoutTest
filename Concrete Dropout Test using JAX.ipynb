{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-418d2724ac7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'darkgrid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import gc\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "from jax.experimental import stax # neural network library\n",
    "from jax.experimental.stax import Dense, Relu # neural network layers\n",
    "from jax.experimental import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "x_train, y_train = make_moons(n_samples = 5000, noise = 0.10)\n",
    "x_test, y_test = make_moons(n_samples = 2000, noise = 0.10)\n",
    "y_test = y_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanStd(predict, params, x, Npred = 50):\n",
    "    # per-example predictions\n",
    "    p = np.concatenate([predict(params, x)[np.newaxis,...] for k in range(Npred)], axis = 0)\n",
    "    return np.mean(p, axis = 0), np.std(p, axis = 0)\n",
    "\n",
    "\n",
    "def makeModel(x_train, y_train):\n",
    "    train_size = len(x_train)\n",
    "\n",
    "    lengthscale = 1e-4\n",
    "    wd = lengthscale**2/train_size\n",
    "    dd = 2./train_size\n",
    "    layers = [200, 100, 50, 5]\n",
    "\n",
    "    net_init, net_apply = stax.serial(\n",
    "        Dense(200), Relu,\n",
    "        Dense(100), Relu,\n",
    "        Dense(50), Relu,\n",
    "        Dense(5), Relu,\n",
    "        Dense(1),\n",
    "    )\n",
    "\n",
    "    L = x_train.shape[1]\n",
    "    out_shape, net_params = net_init((-1, L))\n",
    "    # Make a batched version of the `predict` function\n",
    "    batch_net_apply = vmap(net_apply, in_axes=(None, 0))\n",
    "\n",
    "    def loss(params, x, y):\n",
    "        y_pred = batch_net_apply(params, x)\n",
    "        return -np.mean(np.power(y - y_pred, 2))\n",
    "\n",
    "    # Define a compiled update step\n",
    "    @jit\n",
    "    def step(i, opt_state, opt_update, x1, y1):\n",
    "        p = get_params(opt_state)\n",
    "        g = grad(loss)(p, x1, y1)\n",
    "        return opt_update(i, g, opt_state)\n",
    "\n",
    "    def fit(params, x_train, y_train):\n",
    "        batch_size = 20\n",
    "        Nepochs = 500\n",
    "        opt_init, opt_update, get_params = optimizers.adam(step_size=1e-3)\n",
    "        opt_state = opt_init(params)\n",
    "        for e in range(Nepochs)\n",
    "            for i in range(int(len(x_train)/batch_size)):\n",
    "                opt_state = step(i, opt_state, opt_update, x_train, y_train)\n",
    "        return get_params(opt_state)\n",
    "\n",
    "    params = fit(net_params, x_train, y_train)\n",
    "\n",
    "    return net_apply, params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict, params = makeModel(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(model, x, y, getFunction):\n",
    "    # make countour\n",
    "    mins = [np.min(x[:,0]), np.min(x[:,1])]\n",
    "    maxs = [np.max(x[:,0]), np.max(x[:,1])]\n",
    "    step = [(maxs[0] - mins[0])/50.0, (maxs[1] - mins[1])/50.0]\n",
    "    bx, by = np.mgrid[mins[0]:(maxs[0]+0.5*step[0]):step[0], mins[1]:(maxs[1]+0.5*step[0]):step[1]]\n",
    "    inputs = np.vstack([bx.flatten(), by.flatten()]).T\n",
    "    inputs = inputs.astype(np.float32)\n",
    "\n",
    "    pred_m, pred_s = getFunction(model, inputs, Npred = 50)\n",
    "    pred_m_2d = pred_m.reshape( (-1, bx.shape[1]) )\n",
    "    pred_s_2d = pred_s.reshape( (-1, bx.shape[1]) )\n",
    "\n",
    "    # if one wants to smoothen the results\n",
    "    #for data in [pred_m_2d, pred_s_2d]:\n",
    "    #    data = gaussian_filter(data, 0.1)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = 2, ncols = 1, sharex = True, figsize = (10, 8))\n",
    "    cmap = sns.diverging_palette(250, 12, s=85, l=25, as_cmap=True)\n",
    "    contour_s = ax[0].contourf(bx, by, pred_s_2d, cmap = cmap)\n",
    "    cbar_s = plt.colorbar(contour_s, ax = ax[0])\n",
    "    cbar_s.ax.set_ylabel('Unc.')\n",
    "    contour_m = ax[1].contourf(bx, by, pred_m_2d, cmap = cmap)\n",
    "    cbar_m = plt.colorbar(contour_m, ax = ax[1])\n",
    "    cbar_m.ax.set_ylabel('Mean')\n",
    "    for a in [ax[0], ax[1]]:\n",
    "        a.scatter(x[y == 1,0], x[y == 1,1], color = 'r', marker = 's', s = 5, label = 'y = 1')\n",
    "        a.scatter(x[y == 0,0], x[y == 0,1], color = 'b', marker = 's', s = 5, label = 'y = 0')\n",
    "        a.set(xlabel = 'A', ylabel = 'B', title = '')\n",
    "        a.set_xlim([mins[0], maxs[0]])\n",
    "        a.set_ylim([mins[1], maxs[1]])\n",
    "        a.legend(frameon = True)\n",
    "    ax[0].set_xlabel('')\n",
    "    fig.subplots_adjust(hspace = 0)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(params, x_test, y_test, getFunction = getMeanStd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
